{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa14976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1a3276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 792 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "## Data preprocessing\n",
    "## Training Image Preprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                 samplewise_center=False,\n",
    "                 featurewise_std_normalization=False,\n",
    "                 samplewise_std_normalization=False,\n",
    "                 zca_whitening=False,\n",
    "                 rotation_range=5,\n",
    "                 width_shift_range=0.05,\n",
    "                 height_shift_range=0.05,\n",
    "                 shear_range=0.2,\n",
    "                 zoom_range=0.2,\n",
    "                 channel_shift_range=0.,\n",
    "                 fill_mode='nearest',\n",
    "                 cval=0.,\n",
    "                 horizontal_flip=True,\n",
    "                 vertical_flip=False,\n",
    "                 rescale=1/255)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'images/train',target_size=(64,64),batch_size=64,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "409d6c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a419f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 921 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'images/test',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6db2b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64 , kernel_size=3 , activation='relu' , input_shape=[64,64,3]))\n",
    "cnn.add(tf.keras.laye\n",
    "        rs.MaxPool2D(pool_size=2,strides=2))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64 , kernel_size=3 , activation='relu' ))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2 , strides=2))\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=9 , activation='softmax'))\n",
    "cnn.compile(optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a490f6f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 1.3233 - accuracy: 0.5543 - val_loss: 1.4541 - val_accuracy: 0.4669\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 8s 308ms/step - loss: 1.3057 - accuracy: 0.5303 - val_loss: 1.9402 - val_accuracy: 0.3138\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 7s 292ms/step - loss: 1.2435 - accuracy: 0.5568 - val_loss: 2.0785 - val_accuracy: 0.2432\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 7s 289ms/step - loss: 1.2006 - accuracy: 0.5821 - val_loss: 2.2382 - val_accuracy: 0.2617\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 1.2140 - accuracy: 0.5631 - val_loss: 2.1286 - val_accuracy: 0.2736\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 7s 277ms/step - loss: 1.0926 - accuracy: 0.6048 - val_loss: 2.0545 - val_accuracy: 0.3344\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 1.1107 - accuracy: 0.6035 - val_loss: 2.5290 - val_accuracy: 0.2497\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 7s 278ms/step - loss: 1.1101 - accuracy: 0.6048 - val_loss: 2.0445 - val_accuracy: 0.3149\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 7s 277ms/step - loss: 1.0298 - accuracy: 0.6553 - val_loss: 1.8032 - val_accuracy: 0.4028\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 7s 281ms/step - loss: 1.0370 - accuracy: 0.6402 - val_loss: 2.3901 - val_accuracy: 0.2964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fed273f670>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set , validation_data = test_set , epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76454509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[1.0843463e-32 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "test_image = tf.keras.utils.load_img('images/prediction/bibimbap.jpg',target_size=(64,64))\n",
    "test_image = tf.keras.utils.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image,axis=0)\n",
    "result = cnn.predict(test_image)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c12c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result[0][0]==1:\n",
    "    print('Apple Pie')\n",
    "elif result[0][1]==2:\n",
    "    print('Baby Back Ribs')\n",
    "elif result[0][2]==3:\n",
    "    print('Baklava')\n",
    "elif result[0][3]==4:\n",
    "    print('Beef Carpaccio')\n",
    "elif result[0][4]==5:\n",
    "    print(\"Beef Tartare\")\n",
    "elif result[0][4]==6:\n",
    "    print(\"Beef Salad\")\n",
    "elif result[0][4]==7:\n",
    "    print(\"Beignets\")\n",
    "elif result[0][4]==8:\n",
    "    print(\"Bibimbap\")\n",
    "elif result[0][4]==9:\n",
    "    print(\"Bread Pudding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc585c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eeccf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53639013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fda7be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
